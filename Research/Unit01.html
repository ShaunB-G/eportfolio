<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title> Research Methods and Professional Practice Artefacts e-Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="https://shaunb-g.github.io/eportfolio/assets/css/main.css" />
		<noscript><link rel="stylesheet" href="https://shaunb-g.github.io/eportfolio/assets/css/noscript.css" /></noscript>
		<style>
        .pdf-container {
            width: 50%;
            height: 600px;
            float: left;
            page-break-inside: avoid;
        }

        .pdf-title {
            text-align: center;
            font-size: 20px;
            margin-bottom: 10px;
        }
	

	.border{
		border-bottom: solid 2px white;
		padding: 25px 0;
	}

	.sidebar {
  margin: 0;
  padding: 0;
  width: 150px;
  position: fixed;
  height: 100%;
  overflow: auto;
}
    </style>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<!-- Note: The "styleN" class below should match that of the banner element. -->
					<header id="header" class="alt style2">
						<a href="https://github.com/ShaunB-G/eportfolio/index.html" class="logo"><strong>Shaun</strong> <span>Bell-Gibson</span></a>
						<nav>
							<a href="https://shaunb-g.github.io/eportfolio/#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="https://github.com/ShaunB-G/eportfolio/index.html">Home</a></li>
							<li><a href="https://github.com/ShaunB-G/eportfolio/about.html">About me</a></li>
							<li><a href="https://github.com/ShaunB-G/eportfolio/IntroMod.html">Introductory Module</a></li>
							<li><a href="https://github.com/ShaunB-G/eportfolio/data.html">The Data Professional</a></li>
							<li><a href="https://github.com/ShaunB-G/eportfolio/numerical.html">Numerical Analysis</a></li>
							<li><a href="https://github.com/ShaunB-G/eportfolio/bigdata.html">Deciphering Big Data</a></li>
							<li><a href="https://github.com/ShaunB-G/eportfolio/DataVis.html">Data Visualisation</a></li>
							<li><a href="https://github.com/ShaunB-G/eportfolio/MachineLearning.html">Machine Learning</a></li>
            						<li><a href="https://github.com/ShaunB-G/eportfolio/Research/Research.html">Research Methods and Professional Practice</a></li>
						</ul>
						
	
					</nav>
				
</div>		
	
	<!-- Main -->
					<div id="main" class="alt">

						
						<!-- Two -->
							<section id="two" class="inner">
								<div class="inner">
									<header class="major">
										<h1>Collaborative Discussion 1 - Codes of Ethics and Professional Conduct</h1>
									</header>
									<p>The collaborative discussion discussed the an article by Schwab (2016) written in the World Economic Forum. The objective was to discuss the impact of industry 4.0 on a sector on interest for each contributor. 
									The documents below contain my initial post, the responses to and from my peers and my final summary.</p>
									<h3>Learning Outcomes:</h3>
<li>Understand the applicability and challenges associated with different datasets for the use of machine learning algorithms.</li>
<li>Systematically develop and implement the skills required to be an effective member of a development team in a virtual professional environment, adopting real-life perspectives on team roles and organisation.</li>
										<p></p>
									<h2>Dark UX Patterns</h2>
								<p>In the case study "Dark UX Patterns" provided by the Association of Computing Machinery (ACM), a company deliberately redesigned its website to deceive users into unintended purchases, violating various ethical principles and codes of conduct. The company's use of dark patterns, such as misdirection and hidden costs, directly contradicts the transparency, honesty, and user autonomy principles advocated by the ACM's Code of Ethics. Such deceptive practices erode user trust and undermine the integrity and professionalism of computing professionals involved, who are expected to prioritise user interests and ethical design practices.</p>
<p>Similarly, the British Computer Society (BCS) Code of Conduct emphasises transparency, honesty, and user autonomy. The deliberate deviation from established user interface conventions and the inclusion of additional services without customer consent violate these principles (BCS Code of Conduct, Sections 1.1, 1.2). Additionally, the company's choice of colour scheme, posing significant accessibility challenges, violates the BCS Code's inclusivity and accessibility principles (Section 3 - Public Interest).</p>
<p>While many computing professionals profess a commitment to ethical conduct driven by personal moral compasses, the prevalence of commercial pressures often inhibits their ability to act in accordance with ethical principles (Beattie et al., 2023). However, it is imperative for professionals to recognise their responsibility in safeguarding user interests and upholding ethical standards, even in the face of such pressures.</p>
<p>EU legislation appears not fully equipped to address and keep pace with the fast-evolving and sophisticated nature of dark patterns, causing regulatory gaps that lead to obsolete frameworks and a lack of meaningful oversight (Novelli et al., 2024). This regulatory inadequacy underscores the urgent need for more robust legal regulations and ethical frameworks to protect consumers and ensure a transparent, honest, and inclusive digital environment.</p>
<p>The "Dark UX Patterns" case vividly illustrates ethical challenges within computing, where commercial pressures can compromise professional integrity and user trust. Violations of the ACM and BCS Codes of Conduct highlight the need for more robust ethical frameworks and legal regulations to combat deceptive design practices. Bridging the widening gap between technological advancements and legal oversight is crucial to ensure a transparent, honest, and inclusive digital environment that respects and protects user rights and interests.</p>
<p>References:</p>
<li>BCS Code of conduct (no date) BCS. Available at: https://www.bcs.org/membership-and-registrations/become-a-member/bcs-code-of-conduct/ (Accessed: 20 March 2024). </li>
<li>Beattie, A., Lacey, C. and Caudwell, C. (2023) ‘“it’s like the Wild West”: User experience (UX) designers on ethics and privacy in Aotearoa New Zealand’, Design and Culture, 16(1), pp. 63–82. doi:10.1080/17547075.2023.2211391. </li>
<li>Case: Dark ux patterns - ACM ethics (2018) ACM Ethics - The Official Site of the Association for Computing Machinery’s Committee on Professional Ethics. Available at: https://ethics.acm.org/code-of-ethics/using-the-code/case-dark-ux-patterns/ (Accessed: 20 March 2024). </li>
<li>Novelli, N., Hughes, L., & Smith, R. (2024) The Challenge of Regulating Rapidly Advancing Technologies. European Journal of Law and Technology.</li>

									
								</div>
									
</section>
						
<!-- Three -->
						   <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0 20px;
            background-color: #f4f4f4;
        }
        h2 {
            color: #333;
        }
        a {
            color: #0645AD;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .container {
            max-width: 800px;
            margin: 20px auto;
            padding: 20px;
            background-color: #fff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
    </style>
							<section id="three" class="inner">
								<div class="container">
									<header class="major">
										<h1>Reflective Activity 1 – Ethics in Computing in the age of Generative AI
</h1>
									</header>
									

        <p>The emergence and rapid development of Artificial Intelligence (AI) in recent years have brought about transformative opportunities and significant ethical dilemmas. AI ethics refers to the principles and values that guide the development and deployment of AI technologies, ensuring they are designed and used in a way that is fair, transparent, and accountable (Deckard, 2023). Correa et al. (2023) emphasise the need for better tools to catalogue and compare AI governance documents globally. This is crucial as different countries have varying approaches to regulating generative AI. The lack of a unified global consensus on AI ethics and governance principles can lead to disparities in legal, social, and professional outcomes.</p>

        <h3>Views on Generative AI Across Different Countries</h3>
        <p>The geographic distribution of issuers of ethical AI guidelines indicates a disparity in the global approach to AI ethics, with the majority of guidelines being released by entities in the United States and the European Union (Jobin et al., 2019). This regional concentration of ethical guidelines suggests the need for a more inclusive and globally coordinated approach to AI governance. To build a global consensus, it is important to understand which values are key to all parties. Jobin et al. (2019) analysed 84 sources from around the globe to identify key values that different countries agreed on. From this analysis, eleven overarching ethical values and principles emerged, the most prominent of which are: Transparency (73/84 sources), Justice and Fairness (68/84 sources), and Non-maleficence (60/84 sources).</p>

        <h3>Regulatory Compliance</h3>
        <p>The rapid advancement of emerging technologies starkly contrasts with the sluggish pace of legal oversight, which the EU legislation seems not yet fully equipped to address (Novelli et al., 2024). While technology is moving at an ever-accelerating speed, legislation often finds itself gridlocked, regulations become outdated, and judicial processes proceed at a glacial pace (Marchant, 2011). This disparity not only results in obsolete regulatory frameworks but also in a lack of meaningful oversight. New legal tools and approaches are essential to bridge this widening gap.</p>
        <p>One potential solution is the implementation of agile regulatory frameworks that can quickly adapt to technological advancements. For instance, the EU's General Data Protection Regulation (GDPR) provides a robust foundation for data protection but requires continuous updates to address new AI capabilities and challenges (European Commission, 2024). Additionally, international cooperation through bodies like the OECD and UNESCO can help harmonise AI governance standards, ensuring that ethical guidelines are consistently applied across borders (OECD, 2021; UNESCO, 2022).</p>

        <h3>Social Issues</h3>
        <p>The emergence of ChatGPT and other AI writing tools has had a transformative impact across various industries, offering both significant advantages and potential pitfalls. On the one hand, AI writers streamline tasks such as email composition, report generation, and document creation, thereby enhancing efficiency and reducing the occurrence of human errors. This automation not only saves time but also empowers professionals to concentrate on more intricate, strategic endeavours. On the other hand, an over-reliance on AI poses the risk of diluting interpersonal interactions, potentially eroding the depth and nuance inherent in human communication.</p>
        <p>Schwab & Zahidi (2020) underscore a troubling trend in the contemporary job market: the rate of job destruction is accelerating, while the pace of job creation is decelerating compared to previous years. The advent of AI and automation has revolutionised operational efficiencies across various industries. However, it is of paramount importance not to perceive these advanced technologies solely as direct replacements for specialised human expertise. Rather than displacing human roles, AI should be optimally harnessed as supplementary tools. By doing so, we can empower individuals to delve into and excel in roles that necessitate uniquely human qualities, such as creativity, critical thinking, emotional intelligence, and complex problem-solving. This nuanced integration of AI can foster a symbiotic relationship between technology and human expertise, leading to a more productive and innovative workforce (Jarrahi, 2018).</p>
        <p>To mitigate the negative impacts on employment, governments and organisations should invest in retraining and upskilling programmes. These initiatives can help workers transition to new roles that leverage their uniquely human skills, ensuring that the workforce remains resilient and adaptable in the face of technological change (World Economic Forum, 2020).</p>

        <h3>Ethical Responsibilities of Computing Professionals</h3>
        <p>Hutson (2021) underscores the pervasive biases embedded within AI algorithms, exemplified by inaccurate associations and gender stereotypes. Such biases are symptomatic of the imperfections in the datasets and human inputs that shape these algorithms. Additionally, ethical dilemmas emerge when AI-generated content is utilised without due acknowledgment or credit, prompting concerns about intellectual property rights and equitable compensation.</p>
        <p>Recent ethical controversies surrounding AI usage came to the fore when Disney faced criticism for allegedly employing AI to develop one of its new films during a writer's strike (Whittaker, 2023). This use of AI could potentially undermine the efforts of writers to negotiate better pay and improved working conditions, further disempowering skilled individuals.</p>
        <p>Computing professionals have an ethical responsibility to address these issues by ensuring that AI systems are designed and implemented in ways that minimise bias and respect intellectual property rights. Professional organisations like the ACM and IEEE have developed codes of ethics that provide guidelines for responsible AI development. These codes emphasise the importance of fairness, transparency, accountability, and respect for privacy and human rights (ACM, 2018; IEEE, 2019).</p>

        <h3>Conclusion</h3>
        <p>The rapid advancement of AI technologies offers transformative opportunities but also raises significant ethical, legal, and social concerns. To address these challenges, it is vital to implement transparent and accountable AI algorithms, ensure unbiased and equitable AI systems, and prioritise the safety and well-being of individuals and society. Enhanced global cooperation and consensus are essential to foster a responsible and equitable AI ecosystem. Collaboration among governments, industry leaders, academics, and the public is imperative to develop and deploy AI technologies in a fair, transparent, and accountable manner, maximising benefits while minimising risks.</p>

        <h3>References</h3>
        <ul>
            <li>ACM (2018) ACM Code of Ethics and Professional Conduct. Available at: <a href="https://www.acm.org/code-of-ethics">https://www.acm.org/code-of-ethics</a>.</li>
            <li>Corrêa, N. et al. (2023) Worldwide AI ethics: A review of 200 guidelines and recommendations for AI Governance, 4(10). doi:10.2139/ssrn.4381684.</li>
            <li>Deckard, R.D. (2023) What are ethics in AI? BCS. Available at: <a href="https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/">https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/</a> (Accessed: 27 March 2024).</li>
            <li>European Commission (2024) Data Protection. Available at: <a href="https://ec.europa.eu/info/law/law-topic/data-protection_en">https://ec.europa.eu/info/law/law-topic/data-protection_en</a>.</li>
            <li>Hutson, M. (2021) Robo-writers: The rise and risks of language-generating AI, Nature News. Available at: <a href="https://www.nature.com/articles/d41586-021-00530-0">https://www.nature.com/articles/d41586-021-00530-0</a> (Accessed: 10 January 2024).</li>
            <li>IEEE (2019) IEEE Code of Ethics. Available at: <a href="https://www.ieee.org/about/corporate/governance/p7-8.html">https://www.ieee.org/about/corporate/governance/p7-8.html</a>.</li>
            <li>Jarrahi, M.H. (2018) ‘Artificial Intelligence and the future of work: Human-AI symbiosis in organisational decision making’, Business Horizons, 61(4), pp. 577–586. doi:10.1016/j.bushor.2018.03.007.</li>
            <li>Jobin, A., Ienca, M. and Vayena, E. (2019) ‘The global landscape of AI ethics guidelines’, Nature Machine Intelligence, 1(9), pp. 389–399. doi:10.1038/s42256-019-0088-2.</li>
            <li>Marchant, G.E. (2011) ‘The growing gap between emerging technologies and the law’, The International Library of Ethics, Law and Technology, pp. 19–33. doi:10.1007/978-94-007-1356-7_2.</li>
            <li>Novelli, C. et al. (2024) ‘Generative AI in EU Law: Liability, Privacy, intellectual property, and Cybersecurity’, SSRN Electronic Journal [Preprint]. doi:10.2139/ssrn.4694565.</li>
            <li>OECD (2021) Recommendation of the Council on Artificial Intelligence. Available at: <a href="https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449">https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449</a>.</li>
            <li>Schwab, K. and Zahidi, S. (2020) The Future of Jobs Report 2020, World Economic Forum. Available at: <a href="https://www.weforum.org/publications/the-future-of-jobs-report-2020/">https://www.weforum.org/publications/the-future-of-jobs-report-2020/</a> (Accessed: 22 November 2023).</li>
            <li>UNESCO (2022) Recommendation on the Ethics of Artificial Intelligence. Available at: <a href="https://unesdoc.unesco.org/ark:/48223/pf0000380455">https://unesdoc.unesco.org/ark:/48223/pf0000380455</a>.</li>
            <li>Whittaker, Z. (2023) ‘Disney Criticised for Using AI During Writer’s Strike’, TechCrunch. Available at: <a href="https://techcrunch.com/2023/07/21/disney-ai-writers-strike">https://techcrunch.com/2023/07/21/disney-ai-writers-strike</a> (Accessed: 15 January 2024).</li>
            <li>World Economic Forum (2020) Strategies for the New Economy: Skills as the Currency of the Labour Market. Available at: <a href="https://www.weforum.org/reports/strategies-for-the-new-economy-skills-as-the-currency-of-the-labour-market">https://www.weforum.org/reports/strategies-for-the-new-economy-skills-as-the-currency-of-the-labour-market</a> (Accessed: 22 November 2023).</li>
        </ul>
    </div>
									
</section>			
			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
